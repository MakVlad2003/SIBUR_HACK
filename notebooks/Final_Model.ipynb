{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# CatBoost\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# RDKit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "# PyTorch Lightning\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# MoLeR wrapper\n",
    "from molecule_generation.wrapper import load_model_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Пути ==========\n",
    "TRAIN_CSV = \"/home/oleg28/shteyn/vlad/SIBUR_HACK/data/train_data_all_descriptors.csv\"\n",
    "TEST_CSV  = \"/home/oleg28/shteyn/vlad/SIBUR_HACK/data/test_data_all_descriptors.csv\"\n",
    "MODEL_DIR = \"/home/oleg28/shteyn/vlad/SIBUR_HACK/moler/molecule-generation/molecule_generation/model_checkpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 1. Загрузка и очистка ==========\n",
    "df_train = pd.read_csv(TRAIN_CSV)\n",
    "df_test  = pd.read_csv(TEST_CSV)\n",
    "\n",
    "# Удаляем столбцы с NaN и строки\n",
    "na_cols = df_train.columns[df_train.isna().any()].tolist()\n",
    "df_train.drop(columns=na_cols, inplace=True)\n",
    "df_test .drop(columns=na_cols, inplace=True)\n",
    "df_train.dropna(inplace=True)\n",
    "\n",
    "# Уникальность по ID и SMILES\n",
    "for df in (df_train, df_test):\n",
    "    df.drop_duplicates(subset=['ID'], inplace=True)\n",
    "    df.drop_duplicates(subset=['SMILES'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 2. Табличные дескрипторы ==========\n",
    "y = df_train['LogP'].values\n",
    "X = df_train.drop(columns=['ID','SMILES','LogP','mol'], errors='ignore').select_dtypes(include=[np.number])\n",
    "# Фильтрация\n",
    "miss = X.isna().mean(); drop_m = miss[miss>0.5].index.tolist()\n",
    "vari = X.var(); drop_v = vari[vari<1e-5].index.tolist()\n",
    "corr = X.corr().abs(); upper = corr.where(np.triu(np.ones(corr.shape),1).astype(bool))\n",
    "drop_c = [c for c in upper.columns if any(upper[c]>0.95)]\n",
    "to_drop = set(drop_m + drop_v + drop_c)\n",
    "X_filt = X.drop(columns=list(to_drop))\n",
    "\n",
    "# Импутация и нормализация\n",
    "imp = SimpleImputer(strategy='median')\n",
    "X_desc = imp.fit_transform(X_filt)\n",
    "sc  = StandardScaler()\n",
    "X_desc = sc.fit_transform(X_desc)\n",
    "\n",
    "# Табличные фичи для теста\n",
    "X_test_tab = df_test.drop(columns=['ID','SMILES'], errors='ignore').select_dtypes(include=[np.number])\n",
    "X_test_tab = X_test_tab.drop(columns=list(to_drop), errors='ignore')\n",
    "X_test_tab = sc.transform(imp.transform(X_test_tab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 3. Генерация SMILES-фич ==========\n",
    "# MoLeR-эмбеддинги\n",
    "def generate_moler_embeddings(smiles_list):\n",
    "    with load_model_from_directory(MODEL_DIR, num_workers=8, beam_size=1) as moler:\n",
    "        emb_list = moler.encode(smiles_list)\n",
    "    return np.stack(emb_list)\n",
    "smiles_train = df_train['SMILES'].tolist()\n",
    "smiles_test  = df_test ['SMILES'].tolist()\n",
    "X_emb = generate_moler_embeddings(smiles_train)\n",
    "X_emb_te = generate_moler_embeddings(smiles_test)\n",
    "\n",
    "# Morgan Fingerprints\n",
    "def mol2fp(smiles_list, radius=2, nBits=2048):\n",
    "    fps=[]\n",
    "    for sm in smiles_list:\n",
    "        m = Chem.MolFromSmiles(sm)\n",
    "        v = AllChem.GetMorganFingerprintAsBitVect(m, radius, nBits=nBits)\n",
    "        fps.append(np.array(v, dtype=float))\n",
    "    return np.stack(fps)\n",
    "X_fp    = mol2fp(smiles_train)\n",
    "X_fp_te = mol2fp(smiles_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 4. Lightning MLP ==========\n",
    "class LitMLP(pl.LightningModule):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_dim, 512), torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 256), torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 1)\n",
    "        )\n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "    def forward(self, x):\n",
    "        # Если передаётся список/кортеж, извлекаем первый элемент\n",
    "        if isinstance(x, (tuple, list)):\n",
    "            x = x[0]\n",
    "        return self.net(x).squeeze(1)\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 5. 5-Fold CV базовых моделей ==========\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof_desc = np.zeros(len(X_desc))\n",
    "oof_emb  = np.zeros(len(X_emb))\n",
    "oof_fp   = np.zeros(len(X_fp))\n",
    "pred_desc_test = np.zeros(len(df_test))\n",
    "pred_emb_test  = np.zeros(len(df_test))\n",
    "pred_fp_test   = np.zeros(len(df_test))\n",
    "\n",
    "for i, (tr, va) in enumerate(folds.split(X_desc), 1):\n",
    "    # Splits\n",
    "    dtr, dva = X_desc[tr], X_desc[va]\n",
    "    etr, eva = X_emb[tr],   X_emb[va]\n",
    "    ftr, fva = X_fp[tr],    X_fp[va]\n",
    "    ytr, yva = y[tr],       y[va]\n",
    "\n",
    "    # CatBoost\n",
    "    cb = CatBoostRegressor(iterations=1000, learning_rate=0.05, depth=6,\n",
    "                           loss_function='RMSE', task_type='GPU', verbose=False)\n",
    "    cb.fit(dtr, ytr, eval_set=(dva, yva), early_stopping_rounds=50)\n",
    "    oof_desc[va] = cb.predict(dva)\n",
    "    pred_desc_test += cb.predict(X_test_tab)\n",
    "\n",
    "    # Lightning MLP on embeddings\n",
    "    ds_tr = TensorDataset(torch.Tensor(etr), torch.Tensor(ytr))\n",
    "    ds_va = TensorDataset(torch.Tensor(eva), torch.Tensor(yva))\n",
    "    dl_tr = DataLoader(ds_tr, batch_size=64, shuffle=True)\n",
    "    dl_va = DataLoader(ds_va, batch_size=64)\n",
    "    model_e = LitMLP(X_emb.shape[1])\n",
    "    trainer=pl.Trainer(max_epochs=30, logger=False, enable_checkpointing=False,\n",
    "                       accelerator='gpu' if torch.cuda.is_available() else 'cpu', devices=1)\n",
    "    trainer.fit(model_e, dl_tr, dl_va)\n",
    "    preds_e = trainer.predict(model_e, dl_va)\n",
    "    preds_e = torch.cat([p if isinstance(p, torch.Tensor) else torch.tensor(p) for p in preds_e]).cpu().numpy()\n",
    "    oof_emb[va] = preds_e\n",
    "    # test\n",
    "    test_dl_e = DataLoader(TensorDataset(torch.Tensor(X_emb_te)), batch_size=64)\n",
    "    preds_te_e = trainer.predict(model_e, test_dl_e)\n",
    "    preds_te_e = torch.cat([p if isinstance(p, torch.Tensor) else torch.tensor(p) for p in preds_te_e]).cpu().numpy()\n",
    "    pred_emb_test += preds_te_e\n",
    "\n",
    "    # Lightning MLP on fingerprints\n",
    "    ds_trf = TensorDataset(torch.Tensor(ftr), torch.Tensor(ytr))\n",
    "    ds_vaf = TensorDataset(torch.Tensor(fva), torch.Tensor(yva))\n",
    "    dl_trf = DataLoader(ds_trf, batch_size=64, shuffle=True)\n",
    "    dl_vaf = DataLoader(ds_vaf, batch_size=64)\n",
    "    model_f = LitMLP(X_fp.shape[1])\n",
    "    trainer.fit(model_f, dl_trf, dl_vaf)\n",
    "    preds_f = trainer.predict(model_f, dl_vaf)\n",
    "    preds_f = torch.cat([p if isinstance(p, torch.Tensor) else torch.tensor(p) for p in preds_f]).cpu().numpy()\n",
    "    oof_fp[va] = preds_f\n",
    "    # test\n",
    "    test_dl_f = DataLoader(TensorDataset(torch.Tensor(X_fp_te)), batch_size=64)\n",
    "    preds_te_f = trainer.predict(model_f, test_dl_f)\n",
    "    preds_te_f = torch.cat([p if isinstance(p, torch.Tensor) else torch.tensor(p) for p in preds_te_f]).cpu().numpy()\n",
    "    pred_fp_test += preds_te_f\n",
    "\n",
    "    print(f\"Fold {i} RMSE desc={np.sqrt(mean_squared_error(yva,oof_desc[va])):.4f} \"\n",
    "          f\"emb={np.sqrt(mean_squared_error(yva,oof_emb[va])):.4f} \"\n",
    "          f\"fp={np.sqrt(mean_squared_error(yva,oof_fp[va])):.4f}\")\n",
    "\n",
    "# average test preds\n",
    "pred_desc_test /= folds.get_n_splits()\n",
    "pred_emb_test  /= folds.get_n_splits()\n",
    "pred_fp_test   /= folds.get_n_splits()\n",
    "print(\"OOF RMSE base:\",\n",
    "      np.sqrt(mean_squared_error(y, oof_desc)),\n",
    "      np.sqrt(mean_squared_error(y, oof_emb)),\n",
    "      np.sqrt(mean_squared_error(y, oof_fp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 6. Стэкинг ==========\n",
    "X_stack_tr = np.vstack([oof_desc, oof_emb, oof_fp]).T\n",
    "X_stack_te = np.vstack([pred_desc_test, pred_emb_test, pred_fp_test]).T\n",
    "meta = Ridge()\n",
    "meta.fit(X_stack_tr, y)\n",
    "oof_meta = meta.predict(X_stack_tr)\n",
    "print(\"OOF RMSE meta:\", np.sqrt(mean_squared_error(y, oof_meta)))\n",
    "\n",
    "# Финальный сабмит\n",
    "submission = pd.DataFrame({'ID': df_test['ID'], 'LogP': meta.predict(X_stack_te)})\n",
    "submission.to_csv('submission_stacked.csv', index=False)\n",
    "print(\"Готов файл submission_stacked.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Очищенные исходные данные\n",
    "df_train.to_csv(\"train_clean.csv\", index=False)\n",
    "df_test .to_csv(\"test_clean.csv\",  index=False)\n",
    "\n",
    "# 2. Отфильтрованные табличные дескрипторы\n",
    "X_filt_df = pd.DataFrame(X_filt, columns=X_filt.columns)\n",
    "X_filt_df.to_csv(\"X_filtered_descriptors.csv\", index=False)\n",
    "\n",
    "# 3. Препроцессированные (импутация + масштабирование)\n",
    "X_desc_df = pd.DataFrame(X_desc, columns=X_filt.columns)\n",
    "X_desc_df.to_csv(\"X_desc_scaled.csv\", index=False)\n",
    "\n",
    "# 4. MoLeR‑эмбеддинги и фингерпринты\n",
    "np.save(\"X_emb.npy\",    X_emb)\n",
    "np.save(\"X_emb_te.npy\", X_emb_te)\n",
    "np.save(\"X_fp.npy\",     X_fp)\n",
    "np.save(\"X_fp_te.npy\",  X_fp_te)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moler-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
